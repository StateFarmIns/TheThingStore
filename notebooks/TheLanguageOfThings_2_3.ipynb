{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd06203c-63fa-4738-8e10-2bc9aa912752",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project Management and Oversight for an Expanding Process\n",
    "\n",
    "A technical implementation with pretend project set forth as a Choose your own adventure..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78a03fc-71f4-4eb5-9d28-69135550e346",
   "metadata": {},
   "source": [
    "This Notebook simulates the execution of a particular process many, many, times. It demonstrates how the ThingStore API is used to save, track, and re-use process components; it comes with an accompanying set of functionality that is used behind the scenes. You do not **need** to go digging into that to get the high level takeaway, though it's a great demonstration of how to use this in a technical process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf4a61-cbcd-4e03-a27a-e9b9bccbab78",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71313dc-9b25-4c5d-a621-1d84c17d3adc",
   "metadata": {},
   "source": [
    "This is implemented in Python 3.10, and should be runnable within 4 GB of working memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784419a6-229d-4c58-820c-d8f738e70812",
   "metadata": {},
   "source": [
    "### Ibis - DataFrame solution\n",
    "\n",
    "If you're an analytics professional you should check out the ibis framework. It's the DataFrame solution used here; I chose (this time) to back it with duckdb, instead of Polars or PySpark, but anything developed with ibis can swap the backend and 'just go'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd8958-5ef8-4be4-a16b-418b6115a9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install 'ibis-framework[duckdb]' -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ce345-65b5-4c5c-8f59-7ee1cfef8674",
   "metadata": {},
   "source": [
    "### The Thing Store - Storage and Management Solution\n",
    "\n",
    "If you like nice, neat, orderly Things, and you've not heard of the Thing Store, you chould check it out. I'm going to use it as the data layer which enacts the TS API and will be using it to store, track, and represent my work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e0309-a65f-4c18-ad3f-024daf40694d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -e /root/ThingStore/thethingstore -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2421a4a-67c8-4814-a6cd-69d85798acba",
   "metadata": {},
   "source": [
    "### plotnine - Pretty pictures!\n",
    "\n",
    "Have you ever used ggplot2? Have you ever wished that you could use it in Python? You can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d32b79-2810-4590-8eb5-ca587a74ca79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install plotnine -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ce348-a24b-4d73-9b5d-a7e3adadb500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -e ..[dev] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef12de-0862-4688-8da3-edafdb579695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install thethingstore -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06001a52-dcaf-4a7b-a07c-19e98ae4d3be",
   "metadata": {},
   "source": [
    "### pyvis - Pictures of DAGs\n",
    "\n",
    "Do you like to visualize DAGs? So does PyVis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f832aa-6caa-47bc-b6d8-ef1aead522a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyvis -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c5344-7eb1-48b9-a8be-1d2b368b0439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise Exception('Restart your kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16a88-ff5c-4b6a-ad46-53f2b40f597e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Project Highlights\n",
    "\n",
    "I've got a pretend project in which I'm going to be directed, as part of my duties, to go from data collection to modeling to model publication.\n",
    "\n",
    "So, I'm going to 'do the Thing' to mimic conducting that project. I'm going to pretend to pull data, build a model, etc...\n",
    "\n",
    "I'm going to keep track of what I do, as I do it.\n",
    "\n",
    "I'm not just going to do it once, I'm going to do it *a bunch of times*, because my particular problem is a recurring business problem. (Something akin to 'insurance rating' or 'resource prioritization'.\n",
    "\n",
    "This is neat, because it:\n",
    "\n",
    "1. Creates a lot of functional examples, and\n",
    "2. Shows how to conduct analysis on a lot of functional examples, and\n",
    "3. Builds a corpus to do something neat, next time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58221c0a-159d-4eac-9389-1c3014a64a7e",
   "metadata": {},
   "source": [
    "#### What Things are Useful?\n",
    "\n",
    "There is a distinct set of Things which can be used to describe my project, the notional pieces of which can be seen below.\n",
    "\n",
    "* Draw Data\n",
    "* Model Ready\n",
    "* Model\n",
    "* Aggregate\n",
    "* Review\n",
    "* Publish\n",
    "\n",
    "Each can be represented as a ThingStore compliant data structure, allowing it to be used simply; this will be demonstrated later when we start doing analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f69dce-a919-41ae-b6f3-d6fa18892e10",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "Any one of these Things can be viewed as a probabilistic state within my project by providing next step probabilities. As an example, and **purely notional**, in 65% of our initial data draws we don't discover any new issues, and the SQL we execute 'just works'. 35% of the time we need to go *develop* on our data draw; perhaps there was an issue with the SQL, perhaps the underlying data changed in some manner, perhaps it is 'just because'.\n",
    "\n",
    "Here I've provided initial notional probabilities which could be swapped with measured frequencies in real processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f56cd-ae4c-43c2-a619-bb21e974b80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From the source code for this example; this dictionary has a lot of information and is reused\n",
    "#   across the source.\n",
    "from stepfunctions import functions\n",
    "\n",
    "for f in functions:\n",
    "    print(f'''Function: {f}\n",
    "    Description: {functions[f][\"description\"]}\n",
    "    Potential Next Nodes (p): {functions[f][\"next_node\"]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5dd62-3567-44cb-971e-587bf2fcdbbd",
   "metadata": {},
   "source": [
    "### Required Tools\n",
    "\n",
    "These are the tools that will be used throughout the work; they're collected and described here in some small detail.\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d75fe1-59ae-4175-85b3-514b220e5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis  # DataFrame solution\n",
    "import tempfile  # Temporary storage directory to back ThingStore for transient experiments\n",
    "from ibis import selectors as s  # This allows us to 'say' things in our dataframe manipulation which select one, or many, or no columns dynamically via patterns\n",
    "from ibis import _  # Tool from ibis to allow saying 'the darn DataFrame that flows into this.'  See below for examples and think tidyverse.\n",
    "from numpy.random import default_rng  # You can't simulate stuff without randomness (pseudo or otherwise.)\n",
    "from pyarrow.fs import LocalFileSystem  # This is the filesystem which we'll use to back **our** data layer.\n",
    "# Note that S3 and HDFS are among the implemented filesystems and this can (theoretically) use any fs spec compliant filesystem.\n",
    "from stepfunctions import (\n",
    "    random_project_generator,\n",
    "    single_step,\n",
    "    batch_step,\n",
    "    get_step_files,\n",
    "    step,\n",
    "    convenience_table,\n",
    "    vis_stepwise_thing_dist\n",
    ")  # All the tools developed to back this Notebook\n",
    "# These were all extracted to make this Notebook **not** have 2000 cells.\n",
    "from thethingstore.thing_store_pa_fs import FileSystemThingStore as FSTS  # Heeeeere's Johnny. This is our data layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62471d7b-6992-4b7d-b6ce-548bb37ea7ba",
   "metadata": {},
   "source": [
    "#### Randomness\n",
    "\n",
    "Pseudorandomness and experimentation go hand-in-hand. Simulation is a powerful tool for analysis and requires some sort of hat to pull numbers from that *you* do not make up. Let the computer make those up, for you!\n",
    "\n",
    "The outcome of this is a random number generator from which we can draw a number of different distributional samples of varying characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9c99c-f5a6-480c-9675-0b31c20677c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed my pseudorandomness\n",
    "rng = default_rng(1234124312)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81544bdf-6cc9-4392-82e7-a54188475099",
   "metadata": {},
   "source": [
    "#### Storage (Happy little data layer)\n",
    "\n",
    "Where are we going to store all of our stuff? The default (and the example in this Notebook) use a local filesystem backed ThingStore, but could easily instead back with an S3 filesystem backed, or HDFS backed, or potentially any other fs-spec compliant filesystem.\n",
    "\n",
    "Here, it's simply a temporary local storage directory; after running through the Notebook, and before purging the directory with fire, you may explore using any of the demonstrated tooling and methods to discover exactly in what manner you can explore and reuse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8a4ce-bb1e-413d-b376-90064acf41e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf stupiddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ed4b2-ce6f-48d0-872c-30fdccbea56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obviously notional and temporary directory\n",
    "\n",
    "t = 'stupiddir'\n",
    "data_layer = FSTS(  # <-- This is a FileSystemThingStore, in Python.\n",
    "    metadata_filesystem=LocalFileSystem(),\n",
    "    managed_location=f'{t}/managed_data'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a354c8-0e8a-45b5-a711-5affd20f0929",
   "metadata": {},
   "source": [
    "### Time to get to work!\n",
    "\n",
    "Now we're going to use some simulation tools that were developed for this Notebook to start a number of projects.\n",
    "\n",
    "We're not actually **doing any work**, we're simply saying we are. Here we say that we 'draw data for project x' n times.\n",
    "\n",
    "#### Project generation\n",
    "\n",
    "Short explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21799822-0126-4ac9-9d55-8b8c9bb8ca16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "project_start_points = random_project_generator(\n",
    "    data_layer=data_layer,  # Any TS compliant data layer\n",
    "    n_projects=10,  # The number of projects to generate\n",
    "    seed=4236321  # Fix my pseudorandomness\n",
    ")\n",
    "# Ignore or capture the output below, there's a print statement embedded in the code to allow tracking status\n",
    "#   of a large number of runs in serial which you may turn off / tune as necessary for your case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07d345-fe2d-4d9f-acbe-e2c2524666fe",
   "metadata": {},
   "source": [
    "#### Summarize the initiated projects\n",
    "\n",
    "We're going to pretend that every step is a 'sprint' (roughly two working week time-period); within every sprint we're going to collect the descriptive identifiers for the work done in a single file. We'll reuse that later!\n",
    "\n",
    "To see these files collected you may use this boilerplate as an example. All of these summarization files are going to be given a notional project of -999 to allow distinguishing them.\n",
    "\n",
    "```python\n",
    "t = ibis.memtable(\n",
    "    [\n",
    "        data_layer.get_parameters(_)\n",
    "        for _ in\n",
    "        data_layer.get_dataset(\n",
    "            \"{start_point_fileid}\"\n",
    "        ).to_table().column('FILE_IDS').to_pandas()\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4d5a6-1bba-404e-bfe5-92c20762ce23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize that activity\n",
    "start_point_fileid = data_layer.log(\n",
    "    dataset=ibis.memtable({'FILE_IDS': project_start_points}).to_pandas(),\n",
    "    metadata={'PROJECT': -999, 'THINGTYPE': 'initial_projects'},\n",
    ")\n",
    "print(f\"\"\"Initial Projects Logged. Summary File: {start_point_fileid}\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617d287-9c64-41d8-b223-90cda8e4b51a",
   "metadata": {},
   "source": [
    "#### Simulate the next action\n",
    "\n",
    "This is going to be the template we reuse for conducting every step within our experimentation.\n",
    "\n",
    "We're going to:\n",
    "\n",
    "1. Collect the metadata, (Note that replacement of metadata dataset by logged file and allowing for automatic partitioning or manual partitioning in datasets make the retrieval of metadata for large scale datasets much more feasible.)\n",
    "2. Grab the metadata for the most recent step (see, reusing the file!),\n",
    "3. Randomly select, for each row, the next action based on the specific probabilities,\n",
    "4. Execute that next step to advance each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f070c3-a52e-4606-89f0-dc202ea25efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect the metadata table (todo - prefiltering)\n",
    "t = ibis.memtable(data_layer.browse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9686e-23cb-486c-bc2c-e18fff6ba8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from thethingstore.thing_store_pa_fs import pyarrow_tree\n",
    "pyarrow_tree(\n",
    "    path=f'stupiddir/managed_data',\n",
    "    filesystem=LocalFileSystem(),\n",
    "    max_depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fc9f2-b21f-4bf9-9135-c8f204e13fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate the next step action (this simply returns 'What will I do next, here'.)\n",
    "current_step_files = data_layer.load(get_step_files(\n",
    "    data_layer,\n",
    "    latest=True\n",
    ")).FILE_IDS.to_list()\n",
    "\n",
    "t_1 = ibis.memtable(\n",
    "    data_layer.get_metadata(_) for _ in current_step_files\n",
    ").group_by('THINGTYPE').count().execute()\n",
    "\n",
    "next_step = batch_step(\n",
    "    data_layer=data_layer,\n",
    "    current_state=current_step_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea9343-2ad3-4f36-be9d-9533b598c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the randomly selected steps.\n",
    "steps = next_step.execute().apply(lambda x: single_step(data_layer, x.FILE_ID, x.next_step, t, rng), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e77b3-95ad-44f6-9908-44b7a7c5bb48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize that activity\n",
    "import pandas as pd\n",
    "project_state_fileid = data_layer.log(\n",
    "    dataset=pd.DataFrame({'FILE_IDS': steps}),\n",
    "    metadata={'PROJECT': -999, 'THINGTYPE': 'project_steps'},\n",
    ")\n",
    "print(f\"\"\"Project State Logged. Summary File: {project_state_fileid}\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcdc47-0b42-4eb3-a291-3153b0e09940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_2 = ibis.memtable(\n",
    "    data_layer.get_metadata(_) for _ in data_layer.load(project_state_fileid).FILE_IDS.to_list()\n",
    ").group_by('THINGTYPE').count().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73309328-ef44-41aa-801b-3e54026a8c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fd8fa-31f4-4bd7-80cd-802f953b334c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6bfd0-ab3e-498e-a4c9-7b9c355d6d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect the metadata table (todo - prefiltering)\n",
    "t = ibis.memtable(data_layer.browse())\n",
    "# Simulate the next step action (this simply returns 'What will I do next, here'.)\n",
    "current_step_files = data_layer.load(get_step_files(\n",
    "    data_layer,\n",
    "    latest=True\n",
    ")).FILE_IDS.to_list()\n",
    "\n",
    "next_step = batch_step(\n",
    "    data_layer=data_layer,\n",
    "    current_state=current_step_files\n",
    ")\n",
    "\n",
    "# Execute the randomly selected steps.\n",
    "steps = next_step.execute().apply(lambda x: single_step(data_layer, x.FILE_ID, x.next_step, t, rng), axis=1)\n",
    "\n",
    "# Summarize that activity\n",
    "import pandas as pd\n",
    "project_state_fileid = data_layer.log(\n",
    "    dataset=pd.DataFrame({'FILE_IDS': steps}),\n",
    "    metadata={'PROJECT': -999, 'THINGTYPE': 'project_steps'},\n",
    ")\n",
    "print(f\"\"\"Project State Logged. Summary File: {project_state_fileid}\"\"\")\n",
    "\n",
    "t_3 = ibis.memtable(\n",
    "    data_layer.get_metadata(_) for _ in data_layer.load(project_state_fileid).FILE_IDS.to_list()\n",
    ").group_by('THINGTYPE').count().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96481cd-7021-495b-a690-fe79f3838682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c4e4d-5ec2-4e32-a4ac-6368f54b604c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55487f1-2c69-42c5-985c-67cd42818784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014a662-e5e0-4437-b013-855618ef41c3",
   "metadata": {},
   "source": [
    "Quite handily we've created a convenience function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a1548-715a-4f80-9f4d-9732e0304992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stepfunctions import step\n",
    "project_state_fileid = step(data_layer)\n",
    "project_state_fileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54603e7b-ee50-4d9b-b233-6ad39e9141de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_4 = ibis.memtable(\n",
    "    data_layer.get_metadata(_) for _ in data_layer.load(project_state_fileid).FILE_IDS.to_list()\n",
    ").group_by('THINGTYPE').count().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c786e-0225-40ca-b409-1052fc9f0f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86e792-1aa1-4d1b-82a4-66bcd82146c2",
   "metadata": {},
   "source": [
    "#### Convenience Table\n",
    "\n",
    "This is a table that uses the experimental project metadata `(_.PROJECT=-999)` to label all the folds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf122b7-12b2-4d9f-8382-60b71631f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convenience_table(data_layer, ibis.memtable(data_layer.browse()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a11c07-7cbe-4afb-87e8-949d3263511b",
   "metadata": {},
   "source": [
    "Now we're just going to run this for a number of time steps.\n",
    "\n",
    "This piece isn't parallelized so it's not terribly quick, but it's a functional POC. Feel free to contribute!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091196a-46bc-4f13-9176-42288bf1b369",
   "metadata": {},
   "source": [
    "#### Visualize ThingType distribution by 'step'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e5941-6f83-4901-8d7d-91acd1306642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722e113-7eed-4ad0-b1ca-14ba439e8e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    print(i)\n",
    "    step(data_layer)\n",
    "    display.display(vis_stepwise_thing_dist(data_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b49525-96bf-4644-b69a-888404ca89c6",
   "metadata": {},
   "source": [
    "## Project Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e94c08-f852-4de4-8fda-cda3cf49101b",
   "metadata": {},
   "source": [
    "This visualization represents the empirical CDF at iterative points in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c3b31-2dd7-4d09-b982-93e5f5cfc5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_stepwise_thing_dist(data_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a2bde-5749-4f9a-9ae3-b96a8d667a1e",
   "metadata": {},
   "source": [
    "## Data Discovery\n",
    "\n",
    "All those Things that we logged out there can be looked at; the tools below demonstrate how to do just that and they detail, by Thing, the components that are attached!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dab98f-7295-42f6-bf71-87587852e905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_layer.browse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d921f5-e78a-4fa8-b900-8b74aab3abfa",
   "metadata": {},
   "source": [
    "This visualization demonstrates, by project, how many files are in this data pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9712a-c69c-446e-b834-39f038425871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_layer.browse().groupby('PROJECT').FILE_ID.count()#.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f11ac9-7ddf-439c-a9d4-31dc0f58784e",
   "metadata": {},
   "source": [
    "Here we're going to lift up each of the files used in a specific project; in each one we're going to identify the files that were used as input to these specific pieces of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34732f25-d077-4eb7-8a2b-981a9c651027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_project_data(data_layer, project: int) -> ibis.Table:\n",
    "    def only_what_i_want(x):\n",
    "        return [v for k, v in data_layer.get_parameters(x).items() if 'fileid' in k]\n",
    "    t_metadata = data_layer.browse().query('PROJECT == @project')[['FILE_ID', 'THINGTYPE']]\n",
    "    t_metadata = t_metadata.assign(\n",
    "        upstream = t_metadata.FILE_ID.apply(only_what_i_want)\n",
    "    )\n",
    "\n",
    "    return t_metadata\n",
    "\n",
    "project_data = get_project_data(data_layer, 72854088)\n",
    "project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82456c-8e75-4d59-a878-4f111a726136",
   "metadata": {},
   "source": [
    "Now, we're going to make some pretties!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554edf3-b68f-4c5e-9fa4-fed03c11268f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from json import loads, dumps\n",
    "from stepfunctions import functions\n",
    "\n",
    "def build_alt_text(row_o_data):\n",
    "    \"\"\"Each row has elements required to make a nice string.\"\"\"\n",
    "    header=''\n",
    "    fileid=row_o_data['FILE_ID']\n",
    "    # metadata='JURISDICTION: ' + row_o_data['JURISDICTION'] + ' :::: THINGTYPE: ' + row_o_data['THINGTYPE']\n",
    "    parameters=row_o_data['upstream_params']\n",
    "    output_str = f\"{header}\\nFILE: {fileid}\\n\\n\\tParameters:\\n\"\n",
    "    for k, v in parameters.items():\n",
    "        output_str += f'.     {k}: {v}\\n'\n",
    "    return output_str\n",
    "    # return f\"{header}\\nFILE: {fileid}\\n\\n\\tMetadata:\\n{metadata}\\n\\n\\tParameters:\\n{parameters}\\n\\n\"\n",
    "\n",
    "# I have my data\n",
    "def plot_project(data_layer, project):\n",
    "    # Fetch all the data.\n",
    "    project_data = ibis.memtable(get_project_data(data_layer, project))\n",
    "    # Make the graph\n",
    "    g = Network(\n",
    "        notebook=True,\n",
    "        directed=True,\n",
    "        # neighborhood_highlight=True\n",
    "        # select_menu = True,\n",
    "        # layout='hierarchical',  # Couldn't get this to work right in studio\n",
    "        bgcolor=\"#222222\",\n",
    "        # font_color=\"white\",\n",
    "        heading=str(project)\n",
    "    )\n",
    "    # Clean and clarify node information\n",
    "    node_properties = ibis.memtable(\n",
    "        [\n",
    "            {**v['graph_properties'], 'THINGTYPE': k}\n",
    "            for k, v in functions.items()\n",
    "        ]\n",
    "    )\n",
    "    node_df = project_data.join(\n",
    "        node_properties, 'THINGTYPE'\n",
    "    ).execute()\n",
    "    node_df = node_df.assign(\n",
    "        upstream_params=node_df.FILE_ID.apply(data_layer.get_parameters)\n",
    "    )\n",
    "    node_df = node_df.assign(\n",
    "        title=node_df.apply(build_alt_text, axis=1)\n",
    "    )\n",
    "    # Start adding nodes to it.\n",
    "    for index, node in node_df.iterrows():\n",
    "        g.add_node(\n",
    "            node.FILE_ID,\n",
    "            label=node.THINGTYPE,\n",
    "            title=node.title,  # This is ALT TEXT\n",
    "            color=node.color,\n",
    "            shape=node['shape'],  # Stupid properties!\n",
    "            #size=str(node['count'] * 10),  # Stupid properties!\n",
    "            #mass=(node['count'] * 10),  # Stupid properties!\n",
    "            font={'size': 20, 'color': 'white'}\n",
    "        )\n",
    "    # Start adding edges to it.\n",
    "    for index, node in project_data.execute().iterrows():\n",
    "        if node.upstream:\n",
    "            for upstream_node in node.upstream:\n",
    "                g.add_edge(upstream_node, node.FILE_ID)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9beeb3-42fc-4317-b37f-07f84c3f826a",
   "metadata": {},
   "source": [
    "This particular visualization displays the course of the project from initial data draw all the way to the final publication. It's interactive and has descriptive alt text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079de19b-e2f6-4c0c-afbc-c8cba30e07b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_project(data_layer, 72854088).show('out.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b364a5-77a1-4990-9945-039572ef932c",
   "metadata": {},
   "source": [
    "## Modeling Parameters and Metrics\n",
    "\n",
    "This section unpacks the parameters and metrics into tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689353f8-10cd-420f-85ab-2fa4ecae07f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thing = 'Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257851fc-027d-4755-a632-c18c754e6e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_data = ibis.memtable(get_project_data(data_layer, 72854088)).filter(_.THINGTYPE==thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef95e7-ae24-428e-a253-733ec59889d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_params = ibis.memtable(project_data.execute().FILE_ID.apply(data_layer.get_parameters).to_list()).mutate(i=ibis.row_number())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1972d-aa29-4585-bc97-4b727ab01dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_params.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e88a43-1799-4bde-8d02-878107114d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_metrics = ibis.memtable(project_data.execute().FILE_ID.apply(data_layer.get_metrics).to_list()).mutate(i=ibis.row_number())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a92b7-94c2-4a3c-813e-a0357b2a8db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_metrics.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d9e3a-d557-4d25-a222-b94a716399e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_params.join(t_metrics, 'i').execute()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:067342613937:studio-lifecycle-config/sf-puas-kernelgateway",
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
